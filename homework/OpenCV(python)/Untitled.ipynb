{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影像運算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位元平面分解\n",
    "將灰階影像中處於同一平面上的二進位像素進行組合，獲得一幅二進制值影像，該影像被稱為灰階影像的位元平面，這個過程稱為\"位元平面分解\"。\n",
    "\n",
    "以下範例是使用灰階圖，對這張圖做\"位元平面方解\"，分解後會得到8張位元圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "lena = cv2.imread(\"sample/lena.tiff\", 0)\n",
    "cv2.imshow(\"sample/lena\", lena)\n",
    "r, c = lena.shape\n",
    "# x 為r*c*8 的 0矩陣\n",
    "x = np.zeros((r, c, 8), dtype=np.uint8)\n",
    "for i in range(8):\n",
    "    x[:,:,i] = 2**i\n",
    "r = np.zeros((r, c, 8), dtype=np.uint8)\n",
    "for i in range(8):\n",
    "    r[:,:,i] = cv2.bitwise_and(lena, x[:,:,i]) #and邏輯閘\n",
    "    mask = r[:,:,i] > 0\n",
    "    r[mask] = 255\n",
    "    cv2.imshow(str(i), r[:,:,i])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 影像加密、解密\n",
    "透過 邏輯閘、二進位 運算就可以實現影像加密、解密。\n",
    "加密：原始影像 與 金鑰影像進行逐位元互斥，可實現加密。\n",
    "解密：將加密後的影像與金鑰影像再次進行逐位元互斥，可實現解密。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "練習:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([198,10,20,30])\n",
    "b = np.array([219,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[194],\n",
       "       [  2],\n",
       "       [  0],\n",
       "       [  2]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.bitwise_and(a, b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "加密:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "lena = cv2.imread(\"sample/lena.tiff\", 0)\n",
    "r, c = lena.shape\n",
    "key = np.random.randint(0, 256, size=[r,c], dtype=np.uint8)\n",
    "encryption = cv2.bitwise_xor(lena, key)\n",
    "decryption = cv2.bitwise_xor(encryption, key)\n",
    "cv2.imshow(\"lena\", lena)\n",
    "cv2.imshow(\"key\",key)\n",
    "cv2.imshow(\"encryption\", encryption)\n",
    "cv2.imshow(\"decryption\", decryption)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數字浮水印\n",
    "最低有效位(Least Singification Bit, LSB)指的是一個二進位數字中的第0位(即最低位)。\n",
    "\n",
    "LSB資訊隱藏指的是，將一個需要隱藏的二值影像資訊遷入載體影像的LSB(也就是將載體影像的LSB替換成需要隱藏的二值影像)。\n",
    "\n",
    "如此可以將二值影像隱藏起來。\n",
    "\n",
    "由於二值影像處於載體影像上的LSB，所以對影像的影像非常不明顯，具有隱密性。\n",
    "有必要時直接將載體影像的LSB分析出來，即可獲得嵌入在該位上的二值影像，達到分析秘密資訊的目的。\n",
    "\n",
    "這種資訊隱藏方式也被叫做「數位浮水印」，透過該方式可以實現資訊隱藏、版權認證、身分認證。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-d9cd4c5ab2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 將浮水印影像內的值255處理為1，以方便嵌入\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 後續章節會介紹使用threshold處理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwatermark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m#邏輯判斷 True / False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mwatermark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# 讀取原始載體影像的 shape值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 讀取原始載體影像\n",
    "lena = cv2.imread(\"sample/lena.tiff\", 0)\n",
    "# 讀取浮水印影像\n",
    "watermark = cv2.imread(\"sample/watermark.tiff\", 0)\n",
    "# 將浮水印影像內的值255處理為1，以方便嵌入\n",
    "# 後續章節會介紹使用threshold處理\n",
    "w = watermark[:,:] > 0 #邏輯判斷 True / False\n",
    "watermark[w] = 1\n",
    "# 讀取原始載體影像的 shape值\n",
    "r, c = lena.shape\n",
    "#==============嵌入過程==============\n",
    "# 產生元素值都是254的陣列\n",
    "t254 = np.ones((r,c), dtype=np.uint8)*254\n",
    "# 取得lena影像的高七位(除了LSB最低有效位之外)\n",
    "lenaH7 = cv2.bitwise_and(lenaH7, t254)\n",
    "# 將watermark嵌入lenaH7內\n",
    "e = cv2.bitwise_or(lena7, watermark)\n",
    "#==============分析過程==============\n",
    "# 產生都是1的陣列\n",
    "t1 = np.ones((r,c),dtype=np.uint8)\n",
    "# 從載體影像內分析浮水影像\n",
    "wm = cv2.bitwise_and(e, t1)\n",
    "print(wm)\n",
    "# 將浮水印影像內的值1處理為255，以方便顯示\n",
    "# 後續章節會介紹使用threshold實現\n",
    "w = wm[:,:] > 0\n",
    "wm[w] = 255\n",
    "#==============顯示==================\n",
    "cv2.imshow(\"lena\", lena)\n",
    "cv2.imshow(\"watermark\", watermark*255)\n",
    "cv2.imshow(\"e\", e)\n",
    "cv2.imshow(\"wm\", wm)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 色彩空間轉換\n",
    "RGB、GRAY、YCrCb、HSV、HLS、CIE XYZ、CIE L*a*b、CIE L*u*v、Bayer\n",
    "\n",
    "cv2.cvtColor(src, code [, dstCn])\n",
    "\n",
    "其中:\n",
    "\n",
    "dst : 輸出影像，與原始輸入影像具有同樣的資料型態和深度。\n",
    "\n",
    "src : 原始輸入影像\n",
    "\n",
    "code : 色彩空間轉換碼\n",
    "\n",
    "dstCn : 靶心圖表面的通道數。如果參數為預設的0，則通道數自動透過src或code獲得。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.cvtColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[[116  95  17]\n",
      "  [204  51 141]\n",
      "  [138 188 145]\n",
      "  [102 163  34]]\n",
      "\n",
      " [[ 93  62 152]\n",
      "  [215  62 122]\n",
      "  [ 12 118 177]\n",
      "  [ 83 208 105]]]\n",
      "rst=\n",
      " [[ 74  95 169 117]\n",
      " [ 92  97 124 163]]\n",
      "像素點(1,0)直接計算獲得的值= 92.44399999999999\n",
      "像速點(1,0)使用公式cv2.cvtColor()轉換值= 92\n"
     ]
    }
   ],
   "source": [
    "# BGR轉 灰階\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[2,4,3],dtype=np.uint8) # 隨機產生一張圖\n",
    "rst = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 對圖片做色彩轉換\n",
    "print(\"img=\\n\", img)\n",
    "print(\"rst=\\n\", rst)\n",
    "print(\"像素點(1,0)直接計算獲得的值=\",img[1,0,0]*0.114+img[1,0,1]*0.587+img[1,0,2]*0.299)\n",
    "print(\"像速點(1,0)使用公式cv2.cvtColor()轉換值=\",rst[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[133 147   6 153]\n",
      " [164 117 134  14]]\n",
      "rst=\n",
      " [[[133 133 133]\n",
      "  [147 147 147]\n",
      "  [  6   6   6]\n",
      "  [153 153 153]]\n",
      "\n",
      " [[164 164 164]\n",
      "  [117 117 117]\n",
      "  [134 134 134]\n",
      "  [ 14  14  14]]]\n"
     ]
    }
   ],
   "source": [
    "# 灰階轉BGR\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[2,4],dtype=np.uint8)\n",
    "rst=cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "print(\"img=\\n\", img)\n",
    "print(\"rst=\\n\", rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標記指定顏色"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.inRange()\n",
    "cv2.inRange(src, lowerb, upperb)\n",
    "\n",
    "其中:\n",
    "\n",
    "dst：輸出結果，大小和src一致\n",
    "\n",
    "src：要檢查的陣列or影像\n",
    "\n",
    "lowerb：範圍下界\n",
    "\n",
    "upperb：範圍上界\n",
    "\n",
    "如果src值  在指定範圍內，則dst中對應位置上的值為255\n",
    "\n",
    "如果src值不在指定範圍內，則dst中對應位置上的值為0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[146 227 111 191 133]\n",
      " [130 222  68 227  10]\n",
      " [240  93   3  28  65]\n",
      " [ 96 200 105 200 212]\n",
      " [162 171 236 234  39]]\n",
      "mask=\n",
      " [[255   0 255 255 255]\n",
      " [255   0   0   0   0]\n",
      " [  0   0   0   0   0]\n",
      " [  0 255 255 255   0]\n",
      " [255 255   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[5,5],dtype=np.uint8)\n",
    "min_ = 100\n",
    "max_ = 200\n",
    "mask = cv2.inRange(img, min_, max_)\n",
    "print(\"img=\\n\", img)\n",
    "print(\"mask=\\n\", mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.bitwise_and 使用mask 顯示ROI(有興趣區域)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[9 9 9 9 9]\n",
      " [9 9 9 9 9]\n",
      " [9 9 9 9 9]\n",
      " [9 9 9 9 9]\n",
      " [9 9 9 9 9]]\n",
      "mask=\n",
      " [[1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 1 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 1 0]]\n",
      "roi=\n",
      " [[9 0 0 0 0]\n",
      " [9 0 0 0 0]\n",
      " [9 0 9 9 0]\n",
      " [0 0 9 9 0]\n",
      " [0 0 9 9 0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 圖片\n",
    "img = np.ones([5,5],dtype=np.uint8)*9\n",
    "# mask\n",
    "mask = np.zeros([5,5],dtype=np.uint8)\n",
    "mask[0:3,  0] = 1\n",
    "mask[2:5,2:4] = 1\n",
    "# ROI\n",
    "roi = cv2.bitwise_and(img, img, mask=mask)\n",
    "print(\"img=\\n\",img)\n",
    "print(\"mask=\\n\",mask)\n",
    "print(\"roi=\\n\",roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 顯示特定顏色值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "lena = cv2.imread(\"sample/lena.tiff\")\n",
    "hsv_lena = cv2.cvtColor(lena, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"lena\", hsv_lena)\n",
    "#======選取顏色範圍=======\n",
    "min_ = np.array([10,50,50])\n",
    "max_ = np.array([360,255,255])\n",
    "# 確定藍色區域\n",
    "mask = cv2.inRange(hsv_lena, min_, max_)\n",
    "# 透過cv2.bitwise_and 鎖定藍色區域\n",
    "color_roi = cv2.bitwise_and(hsv_lena, hsv_lena, mask=mask)\n",
    "cv2.imshow('blue', color_roi)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGBA的alpha通道\n",
    "在RGB色彩空間三種通道的基礎上，還可以加上一個A通道，也叫alpha通道，表示透明度。\n",
    "\n",
    "這4種通道的顏色空間被稱為RBGA，PNG影像是一種典型的4通道影像。\n",
    "\n",
    "alpha通道的設定範圍是[0,1]或[0,255]，表示透明到不透明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[[250  73   6]\n",
      "  [ 57 189 112]\n",
      "  [173 227  23]]\n",
      "\n",
      " [[130 225 146]\n",
      "  [ 82 202 137]\n",
      "  [ 31 246 216]]]\n",
      "bgra=\n",
      " [[[250  73   6 255]\n",
      "  [ 57 189 112 255]\n",
      "  [173 227  23 255]]\n",
      "\n",
      " [[130 225 146 255]\n",
      "  [ 82 202 137 255]\n",
      "  [ 31 246 216 255]]]\n",
      "a=\n",
      " [[255 255 255]\n",
      " [255 255 255]]\n",
      "bgra=\n",
      " [[[250  73   6 125]\n",
      "  [ 57 189 112 125]\n",
      "  [173 227  23 125]]\n",
      "\n",
      " [[130 225 146 125]\n",
      "  [ 82 202 137 125]\n",
      "  [ 31 246 216 125]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[2,3,3],dtype=np.uint8)\n",
    "bgra = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "print(\"img=\\n\" , img)\n",
    "print(\"bgra=\\n\",bgra)\n",
    "b,g,r,a = cv2.split(bgra)\n",
    "print(\"a=\\n\",a)\n",
    "a[:,:] = 125\n",
    "bgra = cv2.merge([b,g,r,a])\n",
    "print(\"bgra=\\n\",bgra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 幾何轉換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 縮放cv2.resize()\n",
    "dst = cv2.resize(src, dsize[, fx[, fy[, interpolation]]])\n",
    "\n",
    "其中：\n",
    "\n",
    "dst：輸出影像\n",
    "\n",
    "src：輸入影像\n",
    "\n",
    "dsize：輸出影像大小\n",
    "\n",
    "fx：水平方向的縮放比例\n",
    "\n",
    "fy：垂直方向的縮放比例\n",
    "\n",
    "interpolation：插值方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape= (512, 512, 3)\n",
      "rst.shape= (256, 460, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img =cv2.imread(\"sample/lena.tiff\")\n",
    "rows, cols = img.shape[:2] # 0,1\n",
    "size = (int(cols*0.9), int(rows*0.5))\n",
    "rst = cv2.resize(img, size)\n",
    "print(\"img.shape=\",img.shape)\n",
    "print(\"rst.shape=\",rst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 翻轉cv2.flip()\n",
    "dst = cv2.flip(src, flipCode)\n",
    "\n",
    "其中：\n",
    "\n",
    "dst：輸出影像array\n",
    "\n",
    "src：要處理的原始影像\n",
    "\n",
    "flipCode：旋轉類型(0:繞著x軸翻轉。1、2、3：繞著y軸翻轉。-1,-2,-3：繞著x,y軸同時翻轉)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "x = cv2.flip(img, 0)\n",
    "y = cv2.flip(img, 1)\n",
    "xy = cv2.flip(img, -1)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"x\", x)\n",
    "cv2.imshow(\"y\", y)\n",
    "cv2.imshow(\"xy\", xy)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仿射cv2.warpAffine()\n",
    "仿射轉換：影像可以透過一系列的幾何轉換來實現平移、旋轉、等多種操作。讓轉換保持影像的平直性、平行性。(平直、平行性:經轉換後，直線還是直線、平行線也還是平行線)\n",
    "\n",
    "dst = cv2.warpAffine(src, M, dsize[, flags[, borderMode[, borderValue]]])\n",
    "\n",
    "src:原始影像\n",
    "\n",
    "M:2*3的轉換矩陣。使用不同的M，可以實現不同的仿射轉換。\n",
    "\n",
    "dsize:輸出影像的實際大小\n",
    "\n",
    "flags:內插方法，預設是INTER_LINEAR。當該值為WARP_INVERSE_MAP時，表示M是逆轉換類型。\n",
    "\n",
    "borderMode:邊類型，預設為BORDER_CONSTANT。當該值為BORDER_TRANSPARENT時，表示靶心圖表面內的值不做改變，這些值對應原始影像內的例外值。\n",
    "\n",
    "borderValue代表邊界值，預設為0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平移 (M)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "將原始影像src向右移動100個像素、向下移動200個像素，關係為\n",
    "\n",
    "dst(x,y) = src(x+100,y+200)\n",
    "\n",
    "dst(x,y) = src(1*x + 0*y + 100, 0*x + 1*y + 200)\n",
    "\n",
    "故M = ([[1,0,100]\n",
    "         0,1,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "height, width = img.shape[:2]\n",
    "x = 100\n",
    "y = 200\n",
    "M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "move = cv2.warpAffine(img, M, (width, height))\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"move\", move)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 旋轉 M=cv2.getRotationMatrix2D()\n",
    "M = cv2.getRotationMatrix2D(center ,angle, scale)\n",
    "\n",
    "其中:\n",
    "\n",
    "M:轉換矩陣\n",
    "\n",
    "center:旋轉的中心點\n",
    "\n",
    "angle:旋轉角度(正數:逆時鐘，負數:順時鐘)。\n",
    "\n",
    "scale:轉換尺度(縮放大小)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例:旋轉45度，縮小0.6倍\n",
    "import cv2\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "# 建立 M轉換矩陣\n",
    "height, weight = img.shape[:2]\n",
    "M = cv2.getRotationMatrix2D((height/2, width/2), 45, 0.6)\n",
    "# 旋轉\n",
    "rotate = cv2.warpAffine(img, M, (height, width))\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"move\", rotate)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更複雜的仿射轉換－變形M = cv2.getAffineTransform()\n",
    "M = cv2.getAffineTransform(src, dst)\n",
    "\n",
    "其中:\n",
    "\n",
    "src:輸入影像的三個點座標\n",
    "\n",
    "dst:輸出影像的三個點座標\n",
    "\n",
    "三個點分別對應平行四邊形的 左上、右上、左下角。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "rows, cols, ch = img.shape\n",
    "p1 = np.float32([[0,0],[cols-1,0],[0,rows-1]])\n",
    "p2 = np.float32([[0,rows*0.33],[cols*0.85,rows*0.25],[cols*0.15,rows*0.7]])\n",
    "M = cv2.getAffineTransform(p1, p2)\n",
    "dst = cv2.warpAffine(img, M, (cols,rows))\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"result\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 透視cv2.warpPerspective()\n",
    "dst = cv2.warpPerspective(src, M, dsize[, flags[, borderMode[, bordervalue])\n",
    "\n",
    "dst:經透視處理後的影像\n",
    "\n",
    "src:要透視的影像\n",
    "\n",
    "M:代表3*3轉換矩陣\n",
    "\n",
    "dsize:輸出影像的實際大小\n",
    "\n",
    "flags:內插方法，預設是INTER_LINEAR。當該值為WARP_INVERSE_MAP時，表示M是逆轉換類型。\n",
    "\n",
    "borderMode:邊類型，預設為BORDER_CONSTANT。當該值為BORDER_TRANSPARENT時，表示靶心圖表面內的值不做改變，這些值對應原始影像內的例外值。\n",
    "\n",
    "borderValue代表邊界值，預設為0。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "M跟仿射轉換一樣，可以用函式產生\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "其中:\n",
    "src:輸入影像的4個頂點座標\n",
    "dst:輸出影像的4個頂點座標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "rows,cols = img.shape[:2]\n",
    "print(rows, cols)\n",
    "'''\n",
    "pts1 = np.float32([[150,50],[400,50],[60,450],[310,450]])\n",
    "pts2 = np.float32([[50,50],[rows-50,50],[50,cols-50],[rows-50,cols-50]])\n",
    "'''\n",
    "pts1 = np.float32([[0,0],[0,cols],[rows,0],[rows,cols]])\n",
    "pts2 = np.float32([[0,0],[0,cols],[rows,0],[rows-50,cols-50]])\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "dst = cv2.warpPerspective(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重對映 cv2.remap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多重對映 cv2.remap()\n",
    "dst = cv2.trmap(src, map1 ,map2, interpolation[borderMode[, borderValue]])\n",
    "\n",
    "dst:輸出，與src有相同的大小、類型。\n",
    "\n",
    "src:原始影像\n",
    "\n",
    "map1:參數有兩種可能的值。\n",
    "    * 表示(x,y)點的對映。\n",
    "    * 表示CV_16SC2, CV_32FC1, CV_32FC2類型的(x,y)點的x值。\n",
    "\n",
    "map2:參數同樣有兩種可能的值:\n",
    "    * 當map1表示(x,y)時，該值為空。\n",
    "    * 當map1表示(x,y)點的x值時，該值是CV_16UC1, CV_32FC1類型(x,y)點的y值。\n",
    "    \n",
    "interpolation:插值方式。不支援INTER_AREA\n",
    "\n",
    "borderMode:邊類型，預設為BORDER_CONSTANT。當該值為BORDER_TRANSPARENT時，表示靶心圖表面內的值不做改變，這些值對應原始影像內的例外值。\n",
    "\n",
    "borderValue代表邊界值，預設為0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[149 250 106 146 229]\n",
      " [ 98  53 159  97  17]\n",
      " [ 63  48 131 234 228]\n",
      " [215  12  87 115 147]]\n",
      "mapx=\n",
      " [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "mapy=\n",
      " [[3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]]\n",
      "rst=\n",
      " [[146 146 146 146 146]\n",
      " [146 146 146 146 146]\n",
      " [146 146 146 146 146]\n",
      " [146 146 146 146 146]]\n"
     ]
    }
   ],
   "source": [
    "# 將目標陣列內的值全部 映射成 原始影像內第0行、第3列的像素值\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "rows, cols = img.shape\n",
    "\n",
    "mapx = np.ones(img.shape, np.float32)*0\n",
    "mapy = np.ones(img.shape, np.float32)*3\n",
    "rst = cv2.remap(img, mapy, mapx, cv2.INTER_LINEAR)\n",
    "\n",
    "print(\"img=\\n\", img)\n",
    "print(\"mapx=\\n\", mapx)\n",
    "print(\"mapy=\\n\", mapy)\n",
    "print(\"rst=\\n\", rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複製 cv2.remap()\n",
    "dst = cv2.trmap(src, map1 ,map2, interpolation[borderMode[, borderValue]])\n",
    "\n",
    "    map1:對應位置上的x軸訊息。\n",
    "    map2:對應位置上的y軸訊息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[219 100   8 228 119]\n",
      " [115  81 146 153 198]\n",
      " [158 127 251  73  62]\n",
      " [107 244   9  93  48]]\n",
      "mapx=\n",
      " [[0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]]\n",
      "mapy=\n",
      " [[0. 1. 2. 3. 4.]\n",
      " [0. 1. 2. 3. 4.]\n",
      " [0. 1. 2. 3. 4.]\n",
      " [0. 1. 2. 3. 4.]]\n",
      "rst=\n",
      " [[219 100   8 228 119]\n",
      " [115  81 146 153 198]\n",
      " [158 127 251  73  62]\n",
      " [107 244   9  93  48]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "rows,cols = img.shape\n",
    "mapx = np.zeros(img.shape, np.float32)\n",
    "mapy = np.zeros(img.shape, np.float32)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        mapx.itemset((i,j), i)\n",
    "        mapy.itemset((i,j), j)\n",
    "rst = cv2.remap(img, mapy, mapx, cv2.INTER_LINEAR)\n",
    "\n",
    "print(\"img=\\n\", img)\n",
    "print(\"mapx=\\n\", mapx)\n",
    "print(\"mapy=\\n\", mapy)\n",
    "print(\"rst=\\n\", rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "rows,cols = img.shape[:2]\n",
    "mapx = np.zeros(img.shape[:2], np.float32)\n",
    "mapy = np.zeros(img.shape[:2], np.float32)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        mapx.itemset((i,j), i)\n",
    "        mapy.itemset((i,j), j)\n",
    "rst = cv2.remap(img, mapy, mapx, cv2.INTER_LINEAR)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繞x軸翻轉 cv2.remap()\n",
    " 如果要用cv2.remap()來做x軸翻轉，必須:\n",
    "     x座標軸的值保持不變             ->map1的值保持不變\n",
    "     y座標軸的值以x軸為對稱軸進行交換 ->map2的值調整為「總行數-1-目前行數」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[128  10 229  86 192]\n",
      " [ 97  27  43 142 246]\n",
      " [146 179 169  29 106]\n",
      " [235 217 247 141  88]]\n",
      "mapx=\n",
      " [[3. 3. 3. 3. 3.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "mapy=\n",
      " [[0. 1. 2. 3. 4.]\n",
      " [0. 1. 2. 3. 4.]\n",
      " [0. 1. 2. 3. 4.]\n",
      " [0. 1. 2. 3. 4.]]\n",
      "rst=\n",
      " [[235 217 247 141  88]\n",
      " [146 179 169  29 106]\n",
      " [ 97  27  43 142 246]\n",
      " [128  10 229  86 192]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "rows,cols = img.shape\n",
    "mapx = np.zeros(img.shape, np.float32)\n",
    "mapy = np.zeros(img.shape, np.float32)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        mapx.itemset((i,j), rows-1-i)\n",
    "        mapy.itemset((i,j), j)\n",
    "rst = cv2.remap(img, mapy, mapx, cv2.INTER_LINEAR)\n",
    "\n",
    "print(\"img=\\n\", img)\n",
    "print(\"mapx=\\n\", mapx)\n",
    "print(\"mapy=\\n\", mapy)\n",
    "print(\"rst=\\n\", rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繞y軸翻轉 cv2.remap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[ 47 196 208 151 164]\n",
      " [ 57 167 244 162  11]\n",
      " [109  65  15 251 140]\n",
      " [249  95 191 203  85]]\n",
      "mapx=\n",
      " [[0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]]\n",
      "mapy=\n",
      " [[4. 3. 2. 1. 0.]\n",
      " [4. 3. 2. 1. 0.]\n",
      " [4. 3. 2. 1. 0.]\n",
      " [4. 3. 2. 1. 0.]]\n",
      "rst=\n",
      " [[164 151 208 196  47]\n",
      " [ 11 162 244 167  57]\n",
      " [140 251  15  65 109]\n",
      " [ 85 203 191  95 249]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "rows,cols = img.shape\n",
    "mapx = np.zeros(img.shape, np.float32)\n",
    "mapy = np.zeros(img.shape, np.float32)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        mapx.itemset((i,j), i)\n",
    "        mapy.itemset((i,j), cols-1-j)\n",
    "rst = cv2.remap(img, mapy, mapx, cv2.INTER_LINEAR)\n",
    "\n",
    "print(\"img=\\n\", img)\n",
    "print(\"mapx=\\n\", mapx)\n",
    "print(\"mapy=\\n\", mapy)\n",
    "print(\"rst=\\n\", rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x、y方向互換 cv2.remap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "x, y = img.shape[:2]\n",
    "mapx = np.zeros(img.shape[:2], np.float32)\n",
    "mapy = np.zeros(img.shape[:2], np.float32)\n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        mapy.itemset((i,j), i)\n",
    "        mapx.itemset((i,j), j)\n",
    "rst = cv2.remap(img, mapy ,mapx ,cv2.INTER_LINEAR)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   2., ..., 509., 510., 511.],\n",
       "       [  0.,   1.,   2., ..., 509., 510., 511.],\n",
       "       [  0.,   1.,   2., ..., 509., 510., 511.],\n",
       "       ...,\n",
       "       [  0.,   1.,   2., ..., 509., 510., 511.],\n",
       "       [  0.,   1.,   2., ..., 509., 510., 511.],\n",
       "       [  0.,   1.,   2., ..., 509., 510., 511.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  1.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [  2.,   2.,   2., ...,   2.,   2.,   2.],\n",
       "       ...,\n",
       "       [509., 509., 509., ..., 509., 509., 509.],\n",
       "       [510., 510., 510., ..., 510., 510., 510.],\n",
       "       [511., 511., 511., ..., 511., 511., 511.]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 影像縮放 cv2.remap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\")\n",
    "x, y = img.shape[:2]\n",
    "mapx = np.zeros(img.shape[:2], np.float32)\n",
    "mapy = np.zeros(img.shape[:2], np.float32)\n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        if (0.25*y< i <0.75*y) and (0.25*x< j <0.75*x):\n",
    "            mapx.itemset((i,j),2*(j-y*0.25)+0.5)\n",
    "            mapy.itemset((i,j),2*(i-x*0.25)+0.5)\n",
    "        else:\n",
    "            mapx.itemset((i,j),0)\n",
    "            mapy.itemset((i,j),0)\n",
    "rst = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設定值處理\n",
    "刪除影像內 像素值 高/低於一定值得像素點。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threshold函數\n",
    "cv2.threshold()函數進行設定值化處理\n",
    "\n",
    "retval = cv2.threshold(src, thresh, maxval, type)\n",
    "\n",
    "retval:傳回的設定值\n",
    "\n",
    "dst:設定值分割影像的結果(輸出)，與原始影像具有相同的大小、類型。\n",
    "\n",
    "src:要進行設定值分割的影像，可以是多通道的，8位or32位元浮點數。\n",
    "\n",
    "thresh:要設定的設定值。\n",
    "\n",
    "maxval:當type參數維THRESH_BINARY或THRESH_BINARY_INV類型時，需要設定的最大值。\n",
    "\n",
    "type:設定值分割的類型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.THRESH_BINARY 二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      ", [[ 32  54  80 189  34]\n",
      " [159 231 229  76 152]\n",
      " [207 146  59 146  47]\n",
      " [ 34 181 134 153 158]]\n",
      "t= 127.0\n",
      "rst=\n",
      " [[  0   0   0 255   0]\n",
      " [255 255 255   0 255]\n",
      " [255 255   0 255   0]\n",
      " [  0 255 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "t, rst = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "print(\"img=\\n,\",img)\n",
    "print(\"t=\",t)\n",
    "print(\"rst=\\n\",rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\",0) # 0表示灰階\n",
    "t, rst = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.THRESH_BINARY_INV 反二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\",0) # 0表示灰階\n",
    "t, rst = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.THRESH_TRUNC 截斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      ", [[246 178 146  14 238]\n",
      " [105  80  23  54 119]\n",
      " [ 17 102 155 152 175]\n",
      " [240  75 172 145  58]]\n",
      "t= 127.0\n",
      "rst=\n",
      " [[127 127 127  14 127]\n",
      " [105  80  23  54 119]\n",
      " [ 17 102 127 127 127]\n",
      " [127  75 127 127  58]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "t, rst = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)\n",
    "print(\"img=\\n,\",img)\n",
    "print(\"t=\",t)\n",
    "print(\"rst=\\n\",rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\",0) # 0表示灰階\n",
    "t, rst = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.THRESH_TOZERO_INV\n",
    "    強度值超過 設定值 為0\n",
    "    小於等於則保持不變。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      ", [[192  70 230 226  70]\n",
      " [121 253  23 100 135]\n",
      " [ 25 209  33 201 223]\n",
      " [ 25  31 223 148 239]]\n",
      "t= 127.0\n",
      "rst=\n",
      " [[  0  70   0   0  70]\n",
      " [121   0  23 100   0]\n",
      " [ 25   0  33   0   0]\n",
      " [ 25  31   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "t, rst = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "print(\"img=\\n,\",img)\n",
    "print(\"t=\",t)\n",
    "print(\"rst=\\n\",rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\",0) # 0表示灰階\n",
    "t, rst = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.THRESH_TOZERO\n",
    "強度值 低於 設定值 皆為0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      ", [[186  93  70 231 128]\n",
      " [129  32  18 127 140]\n",
      " [225   3 152 163 158]\n",
      " [246  22 102 194  95]]\n",
      "t= 127.0\n",
      "rst=\n",
      " [[186   0   0 231 128]\n",
      " [129   0   0   0 140]\n",
      " [225   0 152 163 158]\n",
      " [246   0   0 194   0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.random.randint(0,256,size=[4,5],dtype=np.uint8)\n",
    "t, rst = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)\n",
    "print(\"img=\\n,\",img)\n",
    "print(\"t=\",t)\n",
    "print(\"rst=\\n\",rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\",0) # 0表示灰階\n",
    "t, rst = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"rst\", rst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.adaptiveThreshold()\n",
    "dst = cv.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)\n",
    "\n",
    "src:要進行處理的原始影像。必須是8bit單通道影像。\n",
    "\n",
    "maxValue:最大值\n",
    "\n",
    "adaptiveMethod:調整方式。\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "    \n",
    "thresholdType:設定值處理方式。 cv2.THRESH_BINARY或cv2.THRESH_BINARY_INV\n",
    "\n",
    "blockSize:kernel大小，鄰域尺寸，通常3、5、7。\n",
    "\n",
    "C:常數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\",0) # 0表示灰階\n",
    "t1, thd = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "athdMEAN = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 3)\n",
    "athdGAUS = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 3)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"thd\", thd)\n",
    "cv2.imshow(\"athdMEAN\", athdMEAN)\n",
    "cv2.imshow(\"athdGAUS\", athdGAUS)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otsu處理\n",
    "在OpecCV中，透過在函數cv2.threshold()中對參數type的類型多傳遞一個參數cv2.THRESH_OTSU，即可實現Otsu將閥值分割。\n",
    "\n",
    "t, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "其中:\n",
    "1. 參數type增加一個參數值 cv2.THRESH_OTSU\n",
    "2. 設定值為0。在使用OTSU時，設定值要設0，cv2.threshold()最自動找最佳設定值。\n",
    "3. 傳回值t是Otsu方法計算獲得並使用的最佳設定值。\n",
    "\n",
    "如果沒有使用Otsu，情況如下\n",
    "\n",
    "t,thd = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)，其中 t = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[123 123 123 123 123]\n",
      " [123 123 123 123 123]\n",
      " [123 123 126 126 126]\n",
      " [123 123 126 126 126]\n",
      " [123 123 126 126 126]]\n",
      "thd=\n",
      " [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "t1=\n",
      " 127.0\n",
      "otsu=\n",
      " [[  0   0   0   0   0]\n",
      " [  0   0   0   0   0]\n",
      " [  0   0 255 255 255]\n",
      " [  0   0 255 255 255]\n",
      " [  0   0 255 255 255]]\n",
      "t2=\n",
      " 123.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.zeros((5,5),dtype=np.uint8)\n",
    "img[0:6,0:6] = 123\n",
    "img[2:6,2:6] = 126\n",
    "print(\"img=\\n\", img)\n",
    "\n",
    "# 無Otsu\n",
    "t1,thd = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "print(\"thd=\\n\", thd)\n",
    "print(\"t1=\\n\", t1)\n",
    "\n",
    "# 有Otsu\n",
    "t2, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(\"otsu=\\n\", otsu)\n",
    "print(\"t2=\\n\", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/lena.tiff\", 0)\n",
    "t1, thd  = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "t2, otsu = cv2.threshold(img,   0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"thd\", thd)\n",
    "cv2.imshow(\"otsu\", otsu)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影像平滑處理Smoothing Images\n",
    "\n",
    "在盡量保留影像原有訊息的情況下，過濾掉影像內部的雜訊。\n",
    "\n",
    "平滑化處理通常伴隨影像模糊操作，因此也可稱做影像模糊處理(Blurring Images)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 均值濾波average_filter\n",
    "dst = cv2.blur(src, ksize, anchor, borderType)\n",
    "\n",
    "dst:經均值濾波後的結果。\n",
    "\n",
    "src:原始影像。\n",
    "\n",
    "ksize:濾波核大小。\n",
    "\n",
    "anchor:slinding windows的中心位置座標。\n",
    "\n",
    "borderType:邊界模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_blur = cv2.blur(lena_noise, (5,5))\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"result\", lena_noise_blur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方框濾波\n",
    "dst = cv2.boxFilter(src, ddepth, ksize, anchor, normalize, borderType)\n",
    "\n",
    "dst:輸出\n",
    "\n",
    "src:原始影像\n",
    "\n",
    "ddepth:處理影像的影像深度，一般使用-1表示與原始影像使用相同的影像深度。\n",
    "\n",
    "ksize:濾波核大小。\n",
    "\n",
    "anchor:濾波核中心位置。\n",
    "\n",
    "normalize:在濾波時是否進行歸一化。\n",
    "    1:  使用歸一化處理，要用鄰域像素值和除以面積。\n",
    "    0:不使用歸一化處理，直接使用鄰域像素值的和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用normalize=0(不使用歸一化)，所以計算的是kernel(3*3、5*5)像素值之和，所以值都會超過255，顯示為白色。\n",
    "import cv2\n",
    "import numpy as np\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_boxfilter = cv2.boxFilter(lena_noise, -1, (5,5), normalize=0)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"lena_noise_boxfilter\", lena_noise_boxfilter)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用normalize=1(不使用歸一化)\n",
    "import cv2\n",
    "import numpy as np\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_boxfilter = cv2.boxFilter(lena_noise, -1, (5,5), normalize=1)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"lena_noise_boxfilter\", lena_noise_boxfilter)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯濾波 gaussian_filter\n",
    "dst = cv2.GaussianBlur(src, ksize, sigmaX, sigmaY, borderType)\n",
    "\n",
    "dst:輸出\n",
    "\n",
    "src:輸入\n",
    "\n",
    "ksize:濾波核大小\n",
    "\n",
    "sigmaX:旋積核在水平方向上(X軸方向)的標準差，其控制的是加權比例。\n",
    "\n",
    "sigmaY:旋積核在水平方向上(X軸方向)的標準差。如果該值設為0，則只採用sigmaX的值;如果sigmaX、sigmaY都是0，則透過ksize.width、ksize.height計算獲得。\n",
    "    sigmaX = 0.3[(ksize.width -1)*0.5-1]+0.8\n",
    "    sigmaY = 0.3[(ksize.height-1)*0.5-1]+0.8\n",
    "    \n",
    "borderType:邊界模式。\n",
    "\n",
    "通常:\n",
    "    dst = cv2.GaussianBlur(src, ksize, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_GaussianBlur = cv2.GaussianBlur(lena_noise, (5,5), 0, 0)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"lena_noise_GaussianBlur\", lena_noise_GaussianBlur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中值濾波 median_filter\n",
    "因為需要進行排序等操作，中值濾波需要的運算量較大。\n",
    "\n",
    "dst = cv2.medianBlur(src, ksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_medianBlur = cv2.medianBlur(lena_noise, 5)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"lena_noise_medianBlur\", lena_noise_medianBlur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 雙邊濾波\n",
    "雙邊濾波在計算某一個像素點的新值時，考慮以下兩點:\n",
    "    1. 距離訊息(距離越遠，加權越小)。\n",
    "    2. 色彩資訊(色差差別越大，加權越小)。\n",
    "    \n",
    "綜合可慮距離、色彩的加權結果，既能夠有效地去除雜訊，又能夠好好地保護邊緣資訊。\n",
    "\n",
    "dst = cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace, borderType)\n",
    "\n",
    "dst:輸出\n",
    "\n",
    "src:輸入\n",
    "\n",
    "d:濾波時選取的空間距離參數\n",
    "\n",
    "sigmaColor:濾波處理時選取的顏色差值範圍，該值決定了周圍那些像素點能夠參與到濾波中來。\n",
    "\n",
    "sigmaSpace:座標空間中的sigma值。\n",
    "\n",
    "borderType:邊界樣式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_bilateralFilter = cv2.bilateralFilter(lena_noise, 50,100,100)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"lena_noise_bilateralFilter\", lena_noise_bilateralFilter)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯、雙邊濾波 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "lena_noise = cv2.imread(\"sample/lena_noise.jpg\")\n",
    "lena_noise_gaussianBlur = cv2.GaussianBlur(lena_noise, (55,55),0, 0)\n",
    "lena_noise_bilateralFilter = cv2.bilateralFilter(lena_noise, 55, 100, 100)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"lena_noise_gaussianBlur\", lena_noise_gaussianBlur)\n",
    "cv2.imshow(\"lena_noise_bilateralFilter\", lena_noise_bilateralFilter)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自訂 2D旋積核\n",
    "旋積核 = kernel*kernel (旋積核=3x3的空間，也就是slinding windows本身)\n",
    "\n",
    "dst = cv2.filter2D(src, ddepth, kernel, anchor, delta, borderType)\n",
    "\n",
    "ddepth:一般為-1，表示與原始影像使用相同的影像深度。\n",
    "\n",
    "delta:是修正值，是可選項。如果該值存在，會在基礎濾波的結果上加上該值做為最後的濾波處理結果。\n",
    "\n",
    "\n",
    "通常:\n",
    "    dst = cv2.filter2D(src, ddepth, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "lena_noise = cv2.imread(\"lena_noise.jpg\")\n",
    "# 製作 旋積核\n",
    "kernel = np.ones((9,9), np.float32)/81\n",
    "r = cv2.filter2D(lena_noise, -1, kernel)\n",
    "cv2.imshow(\"lena_noise\", lena_noise)\n",
    "cv2.imshow(\"r\", r)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 形態學操作\n",
    "形態學 = 數學形態學 = Mathematical Morphology\n",
    "\n",
    "是影像處理過程中一個非常重要的研究方向。\n",
    "\n",
    "腐蝕、膨脹、閉運算、開運算、形態學梯度(Morphological Gradient)運算、頂帽運算(禮帽)、黑帽運算。\n",
    "\n",
    "其中腐蝕、膨脹操作是形態學的基礎，將其結合能夠實現其他運算(開、閉... ...等)。\n",
    "\n",
    "https://docs.opencv.org/trunk/d9/d61/tutorial_py_morphological_ops.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 腐蝕 Erosion\n",
    "dst = cv2.erode(src, kernel[, anchor[, iterations[, borderType[, borderValue]]]])\n",
    "\n",
    "kernel:腐蝕操作時所採用的結構類型。可以自訂產生，也可透過函數cv2.getStructuringElement()產生\n",
    "\n",
    "iterations:腐蝕操作反覆運算次數，該值預設為1，即只進行一次腐蝕操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[0 0 0 0 0]\n",
      " [0 1 1 1 0]\n",
      " [0 1 1 1 0]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 0 0]]\n",
      "kernel_1=\n",
      " [[1]\n",
      " [1]\n",
      " [1]]\n",
      "erosion_1=\n",
      " [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "=========================\n",
      "kernel_2=\n",
      " [[1 1 1]]\n",
      "erosion_2=\n",
      " [[0 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.zeros((5,5), np.uint8)\n",
    "img[1:4,1:4] = 1\n",
    "kernel_1 = np.ones((3,1), np.uint8)\n",
    "kernel_2 = np.ones((1,3), np.uint8)\n",
    "erosion_1 = cv2.erode(img, kernel_1)\n",
    "erosion_2 = cv2.erode(img, kernel_2)\n",
    "print(\"img=\\n\",img)\n",
    "print(\"kernel_1=\\n\",kernel_1)\n",
    "print(\"erosion_1=\\n\",erosion_1)\n",
    "print(\"=========================\")\n",
    "print(\"kernel_2=\\n\",kernel_2)\n",
    "print(\"erosion_2=\\n\",erosion_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/erode.png\", cv2.IMREAD_UNCHANGED)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "erosion = cv2.erode(img, kernel)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"erosion\", erosion)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 膨脹 Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "kernel=\n",
      " [[1]\n",
      " [1]\n",
      " [1]]\n",
      "dilation=\n",
      " [[0 0 0 0 0]\n",
      " [0 1 1 1 0]\n",
      " [0 1 1 1 0]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.zeros((5,5), np.uint8)\n",
    "img[2,1:4] = 1\n",
    "kernel = np.ones((3,1), np.uint8)\n",
    "dilation = cv2.dilate(img, kernel)\n",
    "print(\"img=\\n\", img)\n",
    "print(\"kernel=\\n\", kernel)\n",
    "print(\"dilation=\\n\",dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations = 1(default)\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/dilate.png\", cv2.IMREAD_UNCHANGED)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilation = cv2.dilate(img, kernel)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"dilation\", dilation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations = 9\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/dilate.png\", cv2.IMREAD_UNCHANGED)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilation = cv2.dilate(img, kernel, iterations=9)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"dilation\", dilation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通用形態學函數\n",
    "dst = cv2.morphologyEx(src, op, kernel[, anchor[, iterations[, borderType[, borderValue]]]])\n",
    "\n",
    "dst:輸出\n",
    "\n",
    "src:輸入\n",
    "\n",
    "op:操作類型。\n",
    "\n",
    "    cv2.MORPH_ERODE  腐蝕\n",
    "    cv2.MORPH_DILATE 膨脹\n",
    "    cv2.MORPH_OPEN   開運算\n",
    "    cv2.MORPH_CLOSE  閉運算\n",
    "    cv2.MORPH_GRADIENT 形態學梯度運算\n",
    "    cv2.MORPH_TOPHAT 頂帽運算\n",
    "    cv2.MORPH_BLACKHAT 黑帽運算\n",
    "    cv2.MORPH_HITMISS 擊中/擊不中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開運算 opening\n",
    "開運算：先將影像腐蝕，再膨脹。\n",
    "\n",
    "用途：可以用於去噪、計數。\n",
    "\n",
    "result = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img1 = cv2.imread(\"sample/erode.png\")\n",
    "img2 = cv2.imread(\"sample/opening.png\")\n",
    "kernel = np.ones((50,50), np.uint8)\n",
    "result1 = cv2.morphologyEx(img1, cv2.MORPH_OPEN, kernel)\n",
    "result2 = cv2.morphologyEx(img2, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"result1\", result1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow(\"result2\", result2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 閉運算 closing\n",
    "閉運算：先將影像膨脹，再腐蝕。\n",
    "\n",
    "用途：關閉前景物體內部的小孔，或去除物體上的小黑點，還可以將不同前景影像進行連接。\n",
    "\n",
    "result = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img1 = cv2.imread(\"sample/closing.png\")\n",
    "img2 = cv2.imread(\"sample/closing1.png\")\n",
    "kernel1 = np.ones((3,3),np.uint8)\n",
    "kernel2 = np.ones((10,10),np.uint8)\n",
    "result1 = cv2.morphologyEx(img1, cv2.MORPH_CLOSE, kernel1, iterations=3)\n",
    "result2 = cv2.morphologyEx(img2, cv2.MORPH_CLOSE, kernel2, iterations=3)\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"result1\", result1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow(\"result2\", result2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態學梯度運算 Morphological Gradient\n",
    "原始影像 -> 膨脹影像 -> 減去腐蝕\n",
    "\n",
    "用途：該操作可以取得原始影像中前景影像的邊緣。\n",
    "\n",
    "result = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"sample/erode.png\", cv2.IMREAD_UNCHANGED)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "result = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"result\", result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hat\n",
    "原始影像 -> 減去 開運算(腐蝕 -> 膨脹)\n",
    "\n",
    "用途：取得影像的雜訊資訊，或獲得比原始影像的邊緣更亮的邊緣資訊。\n",
    "\n",
    "result = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o1 = cv2.imread(\"sample/erode.png\", cv2.IMREAD_UNCHANGED)\n",
    "o2 = cv2.imread(\"sample/lena.tiff\", cv2.IMREAD_UNCHANGED)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "r1 = cv2.morphologyEx(o1, cv2.MORPH_TOPHAT, kernel)\n",
    "r2 = cv2.morphologyEx(o2, cv2.MORPH_TOPHAT, kernel)\n",
    "cv2.imshow(\"img1\", o1)\n",
    "cv2.imshow(\"result1\", r1)\n",
    "cv2.imshow(\"img2\", o2)\n",
    "cv2.imshow(\"result2\", r2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Hat\n",
    "閉運算(膨脹 -> 腐蝕) -> 減去 原始影像\n",
    "\n",
    "用途：\n",
    "\n",
    "    1. 獲取影像內部的小黑點(低強度值)\n",
    "    2. 前景色中的小黑點\n",
    "    3. 比原始影像的邊緣更暗的邊緣\n",
    "    \n",
    "result = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o1 = cv2.imread(\"sample/erode.png\", cv2.IMREAD_UNCHANGED)\n",
    "o2 = cv2.imread(\"sample/lena.tiff\", cv2.IMREAD_UNCHANGED)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "r1 = cv2.morphologyEx(o1, cv2.MORPH_BLACKHAT, kernel)\n",
    "r2 = cv2.morphologyEx(o2, cv2.MORPH_BLACKHAT, kernel)\n",
    "cv2.imshow(\"img1\", o1)\n",
    "cv2.imshow(\"result1\", r1)\n",
    "cv2.imshow(\"img2\", o2)\n",
    "cv2.imshow(\"result2\", r2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核函數\n",
    "retval = cv2.getStructuringElement(shape, ksize[, anchor])\n",
    "\n",
    "shape：形狀類型。\n",
    "\n",
    "    cv2.MORPH_RECT    : 矩陣結構元素。所有元素值都是1\n",
    "    cv2.MORPH_CROSS   : 十字形結構元素。對角線元素值為1\n",
    "    cv2.MORPH_ELLIPSE : 橢圓形結構元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel1=\n",
      " [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "kernel2=\n",
      " [[0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]]\n",
      "kernel3=\n",
      " [[0 0 1 0 0]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "kernel2 = cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "kernel3 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "print(\"kernel1=\\n\", kernel1)\n",
    "print(\"kernel2=\\n\", kernel2)\n",
    "print(\"kernel3=\\n\", kernel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/kernel.png\")\n",
    "kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (20,20))\n",
    "kernel2 = cv2.getStructuringElement(cv2.MORPH_CROSS, (20,20))\n",
    "kernel3 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20,20))\n",
    "dst1 = cv2.dilate(o, kernel1)\n",
    "dst2 = cv2.dilate(o, kernel2)\n",
    "dst3 = cv2.dilate(o, kernel3)\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"dst1\", dst1)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "cv2.imshow(\"dst3\", dst3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影像梯度\n",
    "影像梯度計算的是影像變化的速度。對於影像的邊緣部分，其灰階值變化較大，梯度值也比較大；相反，對於影像中比較平滑的部分，其灰階值變化較小，對應的梯度值也較小。一般情況下，影像梯度計算的是影像的邊緣資訊。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel\n",
    "dst = cv2.Sobel(src, ddepth, dx, dy[, ksize[, scale[, delta]]])\n",
    "\n",
    "    ddepth：影像深度。\n",
    "    dx：x方向上的求導階數。\n",
    "    dy：y方向上的求導階數。\n",
    "    ksize：Sobel核的大小。該值為-1時，則會使用Scharr運算元進行運算。\n",
    "    scale：計算導數值所採用的縮放因數，預設1(無縮放)。\n",
    "    delta：加在dst的值，該值可選，預設為0。\n",
    "    borderType：邊界樣式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數ddepth\n",
    "在函數cv2.Sobel()語法中規定，可以將函數內ddepth參數設定的值為-1，讓處理結果與原始影像保持一致，但是計算梯度時，如果值為負數會被轉成0，所以可能會失去一些細節。為了改善此情況，可以先用高位元(16bit)(-256～256)計算完強度值後，在使用函數轉成8bit(CV_8U)(0～256)，就可以避免失去細節。\n",
    "\n",
    "\n",
    "OpenCV中對參數取絕對值的函數: (作用是將原始影像轉成8bit影像(CV_8U))\n",
    "\n",
    "dst = cv2.convertScaleAbs(src, [, alpha[, beta]])\n",
    "\n",
    "    alpha:調節係數，該值是可選值，預設為1。\n",
    "    beta :調節亮度值，該是預設為0。\n",
    "    這函數的作用等同dst = saturate(src*alpha + beta)，當值超過255時為255。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img=\n",
      " [[-120 -213 -222 -253 -149]\n",
      " [ -30  228  141   48   46]\n",
      " [  88  179 -209 -103 -237]\n",
      " [ 168  -66  127   67 -222]]\n",
      "rst=\n",
      " [[120 213 222 253 149]\n",
      " [ 30 228 141  48  46]\n",
      " [ 88 179 209 103 237]\n",
      " [168  66 127  67 222]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# img = np.random.randint(0,512,size=[4,5], dtype=np.uint16)\n",
    "img = np.random.randint(-256,256,size=[4,5], dtype=np.int16)\n",
    "rst = cv2.convertScaleAbs(img)\n",
    "print(\"img=\\n\", img)\n",
    "print(\"rst=\\n\", rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得影像水平方向的邊緣資訊 ddepth=-1, dx=1, dy=0\n",
    "\n",
    "從結果可以發現，有一半的邊緣資訊沒有顯示出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAABiklEQVR4nO3dSQrDMBAAQSf4/192fhAvdCIhqu4G0Qw+adk2AAAAYDuO0StIvUcvYEGa9jTtrdt03E963abjaNrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9MvHm5j05S/MqfT0LSnaU/TnqY9TXua9jTtTdH0J0eZnI9ayT56ATN7PfvMnPY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5pecuugpaYMYk4H07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne1M0dV8fJ9zXd8mtm/vMaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtDfFnt6Hb13Pypz2NO1p2tO0pykAAADAuQ//ohUSuE3D4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x1962867DCC0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(o,-1,1,0)\n",
    "\n",
    "from PIL import Image\n",
    "sobelx = Image.fromarray(sobelx)\n",
    "sobelx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得影像水平方向的完整邊緣資訊。\n",
    "\n",
    "    參數ddepth = cv2.CV_64F\n",
    "    使用cv2.convertScaleAbs()對cv2.Sobel()取絕對值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAABo0lEQVR4nO3dQQ6CMBRAQTTe/8q6ZqOWPKXAzJaQ0JcfVqUsCwAAAFzE87nt2gHd936AE9K0p2nv2E3nfEkfu+mcNO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0N970ZBtw39m4VHM6A3P6iTntadrTtKdpT9Oepj1Ne5r2/tb0J58y+T7qKh7Dd9x+8BST2rhUc9rTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Y01vdBZKGtDCzenezOn3zCnPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtOe8vp457Y2d13ehs/rWhhZuTnua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepr3xf3Bv9G5X7Mm2CpvTnqY9TXua9jQFAAAA+OwFy7kpAbKh8U8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x1962867DBE0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(o, cv2.CV_64F, 1, 0)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "\n",
    "from PIL import Image\n",
    "sobelx = Image.fromarray(sobelx)\n",
    "sobelx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得影像垂直方向的邊緣資訊 ddepth=-1, dx=0, dy=1\n",
    "\n",
    "    參數ddepth = cv2.CV_64F\n",
    "    使用cv2.convertScaleAbs()對cv2.Sobel()取絕對值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAAAt0lEQVR4nO3dSQ6AMAgAQPX/f9YHaNBipG2cuZoAp26BuCwAAADQ11qVaA+/lpVRYetdANDF3AvZmIu09RQAAAAAAAAAAPiL9j6tuO8rlSod8qOgT8IH9KABAAC0cTdNhg+4mwIAAAAAAAAAAAAAAADAd9qG/17NG844G/kk0YnZSAAAAACAa96kXyc68SYNAAAAAAAAAAAAQIvUT6Yz4hbbsjIq6OkFYFRzb7hjHibs+wAAAAD3DuBiEBmfB1yWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x19628685320>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "sobely = cv2.Sobel(o, cv2.CV_64F, 0, 1)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "\n",
    "from PIL import Image\n",
    "sobely = Image.fromarray(sobely)\n",
    "sobely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得影像垂直方向的邊緣資訊 ddepth=cv2.CV_64F, dx=1, dy=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAAAmUlEQVR4nO3bSw6AIAwFQOL974wnMEi1UuLMlqRhVT55bQ0AAAB+ovfY2oaO1RsAmFazSeunAAAAAAAAAAAAV4LZrpS4WHIGLVhCBg0AACCbt+mItykAAAAAAAAAAAAAAAAAVPFg3nDH2chgMbORAAAAAABv8Cd9hz9pAAAAAAAAAAAAAEr6LH67nkwvAGSoeZlw7gMAAACMnXOIP9EOBhd6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x19628685550>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "sobelxy = cv2.Sobel(o, cv2.CV_64F, 1, 1)\n",
    "sobelxy = cv2.convertScaleAbs(sobelxy)\n",
    "\n",
    "from PIL import Image\n",
    "sobelxy = Image.fromarray(sobelxy)\n",
    "sobelxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將cv2.Sobel() x、y方向的邊緣資訊相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAAB9ElEQVR4nO3dwU7CQBRA0Wr8b+qX69IYYmXK7RT0nC3JTLl5IYF0yrIAAADAuV5mbfSxvP/42mXeZczwevYF/EFvszZ6X9ZZW53NnPamzekhHvND2pz2nntOH/ND2pz2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO2N36e1dd/Xhq1bwnYuedCity2/wZw+gnU9+wqm2flWzWlP056mPU17mvY07Wna07Tnu+nO5TeY0974+agDTscdcswpWHTnAua0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadobO0F2x3nDZzwbedtGV8zp2f7RM3u+G3rj5rSnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2/CZ990ZXzGlv7Hl9Bzyrb1ke93l9X4aWMqc9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtDf+38Y7XTZfW2ddxgzmtDdtTrduB15nXcQc5rSnaU/T3kGnHibZOq8zdPwmZU4BAAAAfvcJmnUsLsSSpD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x1962842C320>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(o, cv2.CV_64F, 1, 0)\n",
    "sobely = cv2.Sobel(o, cv2.CV_64F, 0, 1)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "\n",
    "from PIL import Image\n",
    "sobelxy = Image.fromarray(sobelxy)\n",
    "sobelxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/lena.tiff\", cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(o, cv2.CV_64F, 1, 0)\n",
    "sobely = cv2.Sobel(o, cv2.CV_64F, 0, 1)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "sobelxy11 = cv2.Sobel(o, cv2.CV_64F,1,1)\n",
    "sobelxy11 = cv2.convertScaleAbs(sobelxy11)\n",
    "\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"sobelxy\", sobelxy)\n",
    "cv2.imshow(\"sobelxy11\", sobelxy11)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scharr 運算元及函數使用\n",
    "在離散空間上，有很多方法可以用來計算近似導數。\n",
    "\n",
    "在Sobel 3x3運算元時，可能結果並不太精準。因此有了Scharr，此方法跟Sobel有同的樣速度，但精度更高。\n",
    "\n",
    "Scharr是Sobel的改進(基本上，使用方式一樣)。\n",
    "\n",
    "dst = cv2.Scharr(src, ddrpth, dx, dy[, scale[, delta[, borderType]]])\n",
    "    \n",
    "    ddepth:影像深度\n",
    "    dx:x方向上的導數函數\n",
    "    dy:y方向上的導數函數\n",
    "    scale:計算導數的縮放因數\n",
    "    delta:加到靶心圖上的亮度值。預設為0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAABo0lEQVR4nO3dQQ6CMBRAQTTe/8q6ZqOWPKXAzJaQ0JcfVqUsCwAAAFzE87nt2gHd936AE9K0p2nv2E3nfEkfu+mcNO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0N970ZBtw39m4VHM6A3P6iTntadrTtKdpT9Oepj1Ne5r2/tb0J58y+T7qKh7Dd9x+8BST2rhUc9rTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Y01vdBZKGtDCzenezOn3zCnPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtOe8vp457Y2d13ehs/rWhhZuTnua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepr3xf3Bv9G5X7Mm2CpvTnqY9TXua9jQFAAAA+OwFy7kpAbKh8U8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x22C635FB2B0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "scharrx = cv2.Scharr(o, cv2.CV_64F, 1, 0)\n",
    "scharrx = cv2.convertScaleAbs(scharrx)\n",
    "\n",
    "from PIL import Image\n",
    "scharrx = Image.fromarray(scharrx)\n",
    "scharrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "scharrx = cv2.Scharr(o, cv2.CV_64F, 1, 0)\n",
    "scharry = cv2.Scharr(o, cv2.CV_64F, 0, 1)\n",
    "scharrx = cv2.convertScaleAbs(scharrx)\n",
    "scharry = cv2.convertScaleAbs(scharry)\n",
    "scharrxy = cv2.addWeighted(scharrx, 0.5, scharry, 0.5, 0)\n",
    "\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"scharrxy\", scharrxy)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel和Scharr 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = cv2.imread(\"sample/lena.tiff\", cv2.IMREAD_GRAYSCALE)\n",
    "sobelx = cv2.Sobel(o, cv2.CV_64F, 1, 0)\n",
    "sobely = cv2.Sobel(o, cv2.CV_64F, 0, 1)\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "\n",
    "scharrx = cv2.Scharr(o, cv2.CV_64F, 1, 0)\n",
    "scharry = cv2.Scharr(o, cv2.CV_64F, 0, 1)\n",
    "scharrx = cv2.convertScaleAbs(scharrx)\n",
    "scharry = cv2.convertScaleAbs(scharry)\n",
    "scharrxy = cv2.addWeighted(scharrx, 0.5, scharry, 0.5, 0)\n",
    "\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"sobelxy\", sobelxy)\n",
    "cv2.imshow(\"scharrxy\", scharrxy)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace\n",
    "\n",
    "dst = cv2.Laplacian(src, ddepth[, ksize[, scale[, delta[, borderType]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAACoCAAAAAB4AlLGAAACLElEQVR4nO3d22rcMABAwbT0/385fTSBVmD5SGvvzrwGfDkRineRla8vAAAAeK1f2870fYur2OH3rhONko5/+Dh/9p3q/4PxvZLuG6cfZOM4XeGWk/Szx+k9J+mHj9NbTtLPHqf3pGlP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lvYm3PikUzSxbiXD/o3DK28+N09koH1ze/Am/JQQ+71lx9v9kK3IHJWzWf9jTtadrTtKdpT9Oepj1NezPvncw9CY8+10x/jFhy0KvOj9PZz3yDW5y/+yUHPczd68Q4nTvR+BYnf1FLDnqZ+bSnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2jv5ztmq9w1vum/P4cz7a+fG6ZWrfOK+PYd1L69+0J49P526cfNpT9Oepj1Ne5r2NO1p2tO0p2lP056mPU17mvY07Z3dB23+yz779f3ble95n7hf3+HMnZ8cp/NR7dfHBZr2NO1p2tO0p2lP056mPU17mvY07Wna07SnaU/TnqY9TXua9jTtadrTtKdpT9Oepj1Ne5r2NO1p2tO0p2lv5n9wT/qYd/+3jdPhYtBXrRRdY984fa9uI+bTnqY9TXsb/+4vcceHiWeP0w96mAAAAABe6i9Vyy8pbXx9bAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=339x168 at 0x22C659EDE10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/sobel.png\", cv2.IMREAD_GRAYSCALE)\n",
    "laplace = cv2.Laplacian(o, cv2.CV_64F)\n",
    "laplace = cv2.convertScaleAbs(laplace)\n",
    "\n",
    "from PIL import Image\n",
    "laplace = Image.fromarray(laplace)\n",
    "laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny邊緣檢測\n",
    "是一種使用多級邊緣檢測演算法 檢測邊緣的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大致原理\n",
    "Canny邊緣檢測大致步驟:\n",
    "1. 去噪。\n",
    "2. 計算梯度的幅度與方向。atan2\n",
    "3. 非極大值抑制，即適當地讓邊緣「變瘦」。\n",
    "4. 確定邊緣。過程中將所有邊緣根據 minValue、maxValue來分類邊緣(強邊緣、保留、虛邊緣)，最後保留的邊緣在由是有連接來判斷是否為強邊緣。\n",
    "\n",
    "edges = cv2.Canny(inage, threshold1, threshold2[, apertureSize[, L2gradient]])\n",
    "\n",
    "    edges:邊緣影像\n",
    "    image:8位元輸入影像\n",
    "    apertureSize:Sobel運算元孔徑大小。\n",
    "    L2gradinet:為計算梯度幅度(graient magnitude)的標籤。其預設值為False(L1範數)。\n",
    "        False:L2較精確，兩個方向的導數的平方在開方。\n",
    "        True:L1，直接將兩個方向的導數的絕對值相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同參數設定的邊緣檢測結果\n",
    "import cv2\n",
    "o = cv2.imread(\"sample/lena.tiff\", cv2.IMREAD_GRAYSCALE)\n",
    "r1 = cv2.Canny(o, 128, 200)\n",
    "r2 = cv2.Canny(o,  32, 128)\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"r1\",r1)\n",
    "cv2.imshow(\"r2\",r2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影像金字塔 Gaussian Pyramid\n",
    "由一幅影像的多個不同解析度的子圖所組成的影像集合。\n",
    "\n",
    "金字塔底部是高解析度影像(原始影像)，頂部為低解析度的近似影像。像頂部移動，影像的尺寸和解析度都不斷降低。大部分情況下，每向上移動一級，影像的寬、高都降為原來的二分之一。\n",
    "\n",
    "原圖(0層) -> 高斯濾波 -> 向下採樣(1層) -> 高斯濾波 -> 向下採樣(2層) ...\n",
    "\n",
    "優點：能夠同時留著 低解析的特徵、高解析特徵，也就是會將所以特徵留著。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyrDown\n",
    "dst = cv2.pyrDown(src[, dstsize[, borderType]])\n",
    "\n",
    "    dstsize:靶心圖表面大小\n",
    "    borderType:邊界類型。預設為BORDER_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o.shape (512, 512)\n",
      "r1.shape (256, 256)\n",
      "r2.shape (128, 128)\n",
      "r3.shape (64, 64)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/lena.tiff\", cv2.IMREAD_GRAYSCALE)\n",
    "r1 = cv2.pyrDown(o)\n",
    "r2 = cv2.pyrDown(r1)\n",
    "r3 = cv2.pyrDown(r2)\n",
    "print(\"o.shape\", o.shape)\n",
    "print(\"r1.shape\", r1.shape)\n",
    "print(\"r2.shape\", r2.shape)\n",
    "print(\"r3.shape\", r3.shape)\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"r1\", r1)\n",
    "cv2.imshow(\"r2\", r2)\n",
    "cv2.imshow(\"r3\", r3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyrUp\n",
    "dst = cv2.pyrUp(src[, dstsize[, borderType]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o.shape (66, 68)\n",
      "r1.shape (132, 136)\n",
      "r2.shape (264, 272)\n",
      "r3.shape (528, 544)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/pyrUp.png\", cv2.IMREAD_GRAYSCALE)\n",
    "r1 = cv2.pyrUp(o)\n",
    "r2 = cv2.pyrUp(r1)\n",
    "r3 = cv2.pyrUp(r2)\n",
    "print(\"o.shape\", o.shape)\n",
    "print(\"r1.shape\", r1.shape)\n",
    "print(\"r2.shape\", r2.shape)\n",
    "print(\"r3.shape\", r3.shape)\n",
    "cv2.imshow(\"original\", o)\n",
    "cv2.imshow(\"r1\", r1)\n",
    "cv2.imshow(\"r2\", r2)\n",
    "cv2.imshow(\"r3\", r3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace金字塔  Laplace Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0.shape (512, 512, 3)\n",
      "L1.shape (256, 256, 3)\n",
      "L2.shape (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/lena.tiff\")\n",
    "# =====高斯向下採樣=====\n",
    "G0 = o\n",
    "G1 = cv2.pyrDown(G0)\n",
    "G2 = cv2.pyrDown(G1)\n",
    "G3 = cv2.pyrDown(G2)\n",
    "# =====LaPlace\n",
    "L0 = G0 - cv2.pyrUp(G1)\n",
    "L1 = G1 - cv2.pyrUp(G2)\n",
    "L2 = G2 - cv2.pyrUp(G3)\n",
    "\n",
    "print(\"L0.shape\", L0.shape)\n",
    "print(\"L1.shape\", L1.shape)\n",
    "print(\"L2.shape\", L2.shape)\n",
    "\n",
    "cv2.imshow(\"L0\", L0)\n",
    "cv2.imshow(\"L1\", L1)\n",
    "cv2.imshow(\"L2\", L2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GL = L0 + cv2.pyrUp(G1)\n",
    "G0 = G0 - cv2.pyrUp(G1)\n",
    "cv2.imshow(\"L2\", GL)\n",
    "cv2.imshow(\"G0\", G0)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 高斯金字塔、Laplace金字塔 來恢復 高斯金字塔 內的多層影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0.shape (512, 512, 3)\n",
      "RG0.shape (512, 512, 3)\n",
      "原始影像G0與恢復影像RG0差值的絕對值和： 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/lena.tiff\")\n",
    "# =====產生高斯金字塔=====\n",
    "G0 = o\n",
    "G1 = cv2.pyrDown(G0)\n",
    "G2 = cv2.pyrDown(G1)\n",
    "G3 = cv2.pyrDown(G2)\n",
    "# =====Laplace金字塔=====\n",
    "L0 = G0 - cv2.pyrUp(G1)\n",
    "L1 = G1 - cv2.pyrUp(G2)\n",
    "L2 = G2 - cv2.pyrUp(G3)\n",
    "# =====復原G0=====\n",
    "RG0 = L0 + cv2.pyrUp(G1) #透過Laplace影像還原影像G0\n",
    "print(\"G0.shape\", G0.shape)\n",
    "print(\"RG0.shape\", RG0.shape)\n",
    "result = RG0 - G0 #將 RG0和 G0相減，來確定 還原影像 是否和 原始影像 一樣。\n",
    "#計算result的絕對值，避免正負相減。\n",
    "result = abs(result)\n",
    "# 計算result所有元素的和\n",
    "print(\"原始影像G0與恢復影像RG0差值的絕對值和：\",np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影像輪廓\n",
    "邊緣檢測：邊緣不連續。\n",
    "\n",
    "影像輪廓：將邊緣連續起來形成的整體。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尋找輪廓 cv2.findContours()\n",
    "image, contours, hierarchy = cv2.findContours(image, mode, method)\n",
    "\n",
    "    image    :與函數參數中的原始影像image一致。在OpenCV 4.X中，這個參數已被取消，變成contours, hierarchy = cv2.findContours(image, mode, method)\n",
    "    contours :傳回的輪廓。\n",
    "        (1)type屬性:\n",
    "            type(contours)    >>> <class 'list'>\n",
    "            type(contours[0]) >>> <class 'numpy.ndarray'>\n",
    "        (2)輪廓的個數:len(contours)\n",
    "        (3)每個輪廓的個數:len(contours[0])；contours[0].shape\n",
    "        (4)輪廓內的點:contours[0]\n",
    "    hierarchy:影像的輪廓層次。[Next, Previous, First_Child, Parent]\n",
    "        Next:後一個輪廓的索引編號\n",
    "        Previous:前一個輪廓的索引編號\n",
    "        First_Child:第1個子輪廓的索引編號\n",
    "        Parent:父輪廓的索引編號\n",
    "    \n",
    "    參數中的\n",
    "    image :原始影像。8bit單通道影像。所有非0值被處理為1，0保持不變，也就是灰階圖被處理為二值影像。一般都是先處理成二值影像後再帶入函數使用。\n",
    "    mode  :輪廓搜索模式。\n",
    "        cv2.RETR_EXTERNAL:只檢測外輪廓\n",
    "        cv2.RETR_LIST    :對檢測到的輪廓不建立等級關係\n",
    "        cv2.RETR_CCOMP   :檢索所有輪廓並將他們組織成兩級層次結構。\n",
    "        cv2.RETR_TREE:建立一個等級樹結構的輪廓。\n",
    "    method:輪廓的近似方法。\n",
    "        cv2.CHAIN_APPROX_SIMPLE:儲存所有的輪廓點，相鄰兩個點的像素位置差不超過1，即max(abs(x1-x2))，abs(y2-y1)=1\n",
    "        cv2.CHAIN_APPROX_SIMPLE:壓縮水平方向、垂直方向、對角線方向的元素，只保留該方向的終點目標。EX:在極端情況下，一個舉行只需用4個點來儲存輪廓資訊。\n",
    "        cv2.CHAIN_APPROX_TC89_L1:使用teh-Chinl chain近似演算法的一種風格。\n",
    "        cv2.CHAIN_APPROX_TC89_KCOS:使用teh-Chinl chain近似演算法的一種風格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 繪製影像輪廓 cv2.drawContours()\n",
    "image = cv2.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]])\n",
    "\n",
    "    image:要繪製的影像。繪製後，image會變成包含輪廓的影像。\n",
    "    contours:需要繪製的輪廓，類型是list。\n",
    "    contourIdx:需要繪製的邊緣索引。告訴opencv要繪製一條還是全部輪廓。整數或0表示繪製該索引的輪廓。預設為-1，表示全部輪廓。\n",
    "    color:繪製的顏色\n",
    "    thickness:可選參數。線條粗細。預設為-1，表示實心輪廓。\n",
    "    lineType:可選參數。表示繪製輪廓時所用的線型。\n",
    "    hierarchy:對應cv2.findContours()所輸出的層次資訊。\n",
    "    maxLevel:控制所繪製的輪廓層次的深度。如果該值為0，表示僅繪製第0層的輪廓，如果為其他非0正數，表示繪製最高層和以下的相同數量層級的輪廓。\n",
    "    offset:偏移參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread(\"sample/contours.png\")\n",
    "\n",
    "cv2.imshow(\"original\", o)\n",
    "gray = cv2.cvtColor(o, cv2.COLOR_BGR2GRAY)\n",
    "ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "o = cv2.drawContours(o, contours, -1, (0,0,255), 10) # 紅色，粗細為5\n",
    "\n",
    "cv2.imshow(\"result\", o)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "o = cv2.imread(\"sample/lena.tiff\")\n",
    "cv2.imshow(\"original\", o)\n",
    "gray = cv2.cvtColor(o, cv2.COLOR_BGR2GRAY)\n",
    "ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "o = cv2.drawContours(o, contours, -1, (0,0,255), 1) # 紅色，粗細為5\n",
    "\n",
    "mask = np.zeros(o.shape, np.uint8)\n",
    "mask = cv2.drawContours(mask, contours, -1, (255,255,255), -1)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "location = cv2.bitwise_and(o, mask)\n",
    "cv2.imshow(\"location\", location)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩特徵\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "266.042px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
